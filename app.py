# -*- coding: utf-8 -*-
import logging
import os
from pathlib import Path
from typing import List, Optional, Tuple
from dotenv import load_dotenv
from queue import Empty, Queue
from threading import Thread
import gradio as gr
from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.chat_models import ChatOpenAI
from langchain.prompts import HumanMessagePromptTemplate
from langchain.schema import AIMessage, BaseMessage, HumanMessage, SystemMessage
from callback import QueueCallback

# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
# è®¾ç½®å¯é€‰æ‹©çš„æ¨¡å‹
MODELS_NAMES = ["gpt-3.5-turbo", "gpt-4"]
DEFAULT_TEMPERATURE = 0.7
ChatHistory = List[str]
logging.basicConfig(
    format="[%(asctime)s %(levelname)s]: %(message)s", level=logging.INFO
)
human_message_prompt_template = HumanMessagePromptTemplate.from_template("{text}")
# åŠ è½½ç³»ç»Ÿæç¤º
default_system_prompt = Path("E:\python-prj\gradioGPT-main\src\prompts\system.prompt").read_text(encoding="utf-8")


# åˆ›å»ºèŠå¤©æœºå™¨äººç•Œé¢ï¼Œå¹¶ä¿å­˜èŠå¤©è®°å½•
def on_message_button_click(
        chat: Optional[ChatOpenAI],
        message: str,
        # ç”¨æˆ·è¾“å…¥ä¿¡æ¯
        chatbot_messages: ChatHistory,
        # åŒ…å«AIMessageã€HumanMessageå’ŒSystemMessage
        messages: List[BaseMessage],
) -> Tuple[ChatOpenAI, str, ChatHistory, List[BaseMessage]]:
    if chat is None:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ.get("OPENAI_API_KEY")
        queue = Queue()
        # åˆ›å»ºèŠå¤©æœºå™¨äºº
        chat = ChatOpenAI(
            model_name=MODELS_NAMES[0],
            temperature=DEFAULT_TEMPERATURE,
            streaming=True,
            callbacks=([QueueCallback(queue)]),
        )

    else:
        # å–å‡ºåˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ª
        queue = chat.callbacks[0].queue

    job_done = object()

    logging.info(f"æ­£åœ¨è¿›è¡Œæé—®, é—®é¢˜-->{message}")
    # å°†ç”¨æˆ·è¾“å…¥çš„ä¿¡æ¯ä¹Ÿä¸€å¹¶åŠ å…¥åˆ°è®°å½•ä¸­
    messages.append(HumanMessage(content=message))
    chatbot_messages.append((message, ""))


    # è¿æ¥ç»´åŸºç™¾ç§‘
    tools = load_tools(['wikipedia'], llm=chat)

    agent = initialize_agent(
        tools,
        chat,
        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
        verbose=True,
        handle_parsing_errors="Check your output and make sure it conforms",
    )
    # print(messages)

    agent.run(input=[message, chatbot_messages])


    # æ‰§è¡ŒèŠå¤©æœºå™¨äººçš„ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
    # def task():
    #     chat(messages)
    #     queue.put(job_done)
    #
    # # åˆ›å»ºä¸€ä¸ªçº¿ç¨‹å¹¶åœ¨å…¶ä¸­è¿è¡Œç”Ÿæˆä»»åŠ¡
    # t = Thread(target=task)
    # t.start()
    # ç”¨äºä¿å­˜ç”Ÿæˆçš„ç»“æœ
    content = ""
    # è¯»å–é˜Ÿåˆ—ä¸­æœ€åä¸€ä¸ªç”Ÿæˆç»“æœ
    while True:
        try:
            next_token = queue.get(True, timeout=1)
            if next_token is job_done:
                break
            content += next_token
            chatbot_messages[-1] = (message, content)
            yield chat, "", chatbot_messages, messages
        except Empty:
            continue
    # å°†ç»“æœåŠ å…¥åˆ°è®°å½•ä¸­
    messages.append(AIMessage(content=content))
    logging.debug(f"reply = {content}")
    logging.info(f"Done!")

    print(chatbot_messages, messages)

    return chat, "", chatbot_messages, messages


# å¤„ç†ç³»ç»Ÿæç¤ºçš„æ›´æ”¹
def system_prompt_handler(value: str) -> str:
    return value


# æ¸…é™¤èŠå¤©è®°å½•
def on_clear_button_click(system_prompt: str) -> Tuple[str, List, List]:
    return "", [], [SystemMessage(content=system_prompt)]


# åº”ç”¨è®¾ç½®ï¼ŒåŒ…æ‹¬æ¨¡å‹model_nameå’Œtemperature
def on_apply_settings_button_click(
        system_prompt: str, model_name: str, temperature: float
):
    logging.info(
        f"å½“å‰è®¾ç½®: model_name={model_name}, temperature={temperature}"
    )
    chat = ChatOpenAI(
        model_name=model_name,
        temperature=temperature,
        streaming=True,
        callbacks=[QueueCallback(Queue())],
    )
    # æ¸…é™¤é˜Ÿåˆ—queue
    chat.callbacks[0].queue.empty()
    return chat, *on_clear_button_click(system_prompt)


# å‰ç«¯ç•Œé¢ï¼Œå¯¹æ–¹æ³•è¿›è¡Œå°è£…
with gr.Blocks(
        css="""
        #col_container {
        width: 700px;
        margin-left: auto;
        margin-right: auto;
        }
        #chatbot {
        height: 400px;
        overflow: auto;
        background-color: white;
        }"""
) as demo:
    # è®¾ç½®åˆå§‹çŠ¶æ€
    system_prompt = gr.State(default_system_prompt)
    messages = gr.State([SystemMessage(content=default_system_prompt)])
    # è®¾ç½®chatåˆå§‹çŠ¶æ€ä¸ºç©º
    chat = gr.State(None)

    with gr.Column(elem_id="col_container"):
        # æ ‡é¢˜
        gr.Markdown("# æ¬¢è¿è¿›å…¥åˆ˜æ¿›ã®GPT! ğŸŒŸğŸš€")
        gr.Markdown(
            "â€”â€”å¯è‡ªå®šä¹‰æƒ…æ„Ÿçš„æ™ºèƒ½èŠå¤©æœºå™¨äºº"
        )
        with gr.Column():
            system_prompt_area = gr.TextArea(
                default_system_prompt, lines=4, label="æœºå™¨äººæƒ…æ„Ÿè®¾ç½®ï¼ˆå¯æ ¹æ®ä»¥ä¸‹å†…å®¹è‡ªè¡Œä¿®æ”¹æœºå™¨äººæƒ…æ„Ÿï¼‰",
                interactive=True
            )
            # è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶å¯è¾“å…¥
            system_prompt_area.input(
                system_prompt_handler,
                inputs=[system_prompt_area],
                outputs=[system_prompt],
            )
            system_prompt_button = gr.Button("å†™å…¥")

        chatbot = gr.Chatbot(label="è®°å½•")
        with gr.Column():
            message = gr.Textbox(label="è¾“å…¥")
            message.submit(
                on_message_button_click,
                inputs=[chat, message, chatbot, messages],
                outputs=[chat, message, chatbot, messages],
                queue=True,
            )
            message_button = gr.Button("æäº¤", variant="primary")
            message_button.click(
                on_message_button_click,
                inputs=[chat, message, chatbot, messages],
                outputs=[chat, message, chatbot, messages],
            )
        with gr.Row():
            with gr.Column():
                clear_button = gr.Button("æ¸…ç©º")
                clear_button.click(
                    on_clear_button_click,
                    inputs=[system_prompt],
                    outputs=[message, chatbot, messages],
                    queue=False,
                )
            with gr.Accordion("è‡ªå®šä¹‰", open=False):
                model_name = gr.Dropdown(
                    choices=MODELS_NAMES, value=MODELS_NAMES[0], label="model"
                )
                temperature = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    value=0.7,
                    step=0.1,
                    label="temperature",
                    interactive=True,
                )
                apply_settings_button = gr.Button("åº”ç”¨")
                apply_settings_button.click(
                    on_apply_settings_button_click,
                    [system_prompt, model_name, temperature],
                    [chat, message, chatbot, messages],
                )

        system_prompt_button.click(
            on_apply_settings_button_click,
            [system_prompt, model_name, temperature],
            [chat, message, chatbot, messages],
        )

if __name__ == "__main__":
    demo.queue()
    demo.launch()
